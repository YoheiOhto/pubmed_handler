{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64eb7f37",
   "metadata": {},
   "source": [
    " * @ Author: Yohei Ohto\n",
    " * @ Create Time: 2025-11-28 20:27:05\n",
    " * @ Modified time: 2025-11-28 20:28:31\n",
    " * @ Description: meddra term search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64b5115",
   "metadata": {},
   "source": [
    "1. SOC  (System Organ Class)       : 器官別大分類 (最上位)  \n",
    "    │  \n",
    "    └─ 2. HLGT (High Level Group Term) : 高位グループ語  \n",
    "         │  \n",
    "         └─ 3. HLT  (High Level Term)       : 高位語  \n",
    "              │  \n",
    "              └─ 4. PT   (Preferred Term)        : 基本語 ★分析・集計の標準単位  \n",
    "                   │  \n",
    "                   └─ 5. LLT  (Lowest Level Term)     : 下層語 (入力用語・シノニム)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e63e5866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from elasticsearch import Elasticsearch\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f2ec17",
   "metadata": {},
   "source": [
    "#  化合物名をすでに含んでいる文でのみ検索する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233ef067",
   "metadata": {},
   "source": [
    "# pubmed × drugbank × meddra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15669f0",
   "metadata": {},
   "source": [
    "## drugbank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72a83bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugbank = pd.read_csv(\"/workspace/99-NAS_data/pubmed/pubmed_drugbank_sentence/drugbank_sentences_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b5f2053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug_name</th>\n",
       "      <th>PMID</th>\n",
       "      <th>SENTID</th>\n",
       "      <th>SENTENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lepirudin</td>\n",
       "      <td>10073268</td>\n",
       "      <td>36206825</td>\n",
       "      <td>The central role of thrombin generation in thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lepirudin</td>\n",
       "      <td>10209835</td>\n",
       "      <td>36692541</td>\n",
       "      <td>HIT type II was presumed and recanalization wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lepirudin</td>\n",
       "      <td>10209835</td>\n",
       "      <td>36692547</td>\n",
       "      <td>This case report illustrates the complicated d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lepirudin</td>\n",
       "      <td>10218429</td>\n",
       "      <td>36748792</td>\n",
       "      <td>The patient was treated with lepirudin at body...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lepirudin</td>\n",
       "      <td>10229643</td>\n",
       "      <td>36825405</td>\n",
       "      <td>Lepirudin has a short half-life, and only 50-6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   drug_name      PMID    SENTID  \\\n",
       "0  Lepirudin  10073268  36206825   \n",
       "1  Lepirudin  10209835  36692541   \n",
       "2  Lepirudin  10209835  36692547   \n",
       "3  Lepirudin  10218429  36748792   \n",
       "4  Lepirudin  10229643  36825405   \n",
       "\n",
       "                                            SENTENCE  \n",
       "0  The central role of thrombin generation in thi...  \n",
       "1  HIT type II was presumed and recanalization wa...  \n",
       "2  This case report illustrates the complicated d...  \n",
       "3  The patient was treated with lepirudin at body...  \n",
       "4  Lepirudin has a short half-life, and only 50-6...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugbank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e83b3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40256637 30324930 30324930\n"
     ]
    }
   ],
   "source": [
    "tatget_sentid = list(set(drugbank['SENTID'].tolist()))\n",
    "print(len(drugbank), len(drugbank['SENTID'].unique()), len(tatget_sentid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d58fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tatget_sent_id = sorted(tatget_sentid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0886727",
   "metadata": {},
   "source": [
    "## meddra data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c58746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "soc = pd.read_csv(\"/workspace/99-NAS_data/meddra/240828_processed_yoshikawa/soc.tsv\", sep=\"\\t\")\n",
    "hlgt = pd.read_csv(\"/workspace/99-NAS_data/meddra/240828_processed_yoshikawa/hlgt.tsv\", sep=\"\\t\")\n",
    "hlt = pd.read_csv(\"/workspace/99-NAS_data/meddra/240828_processed_yoshikawa/hlt.tsv\", sep=\"\\t\")\n",
    "pt = pd.read_csv(\"/workspace/99-NAS_data/meddra/240828_processed_yoshikawa/pt.tsv\", sep=\"\\t\")\n",
    "llt = pd.read_csv(\"/workspace/99-NAS_data/meddra/240828_processed_yoshikawa/llt.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb10471d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 337 1738 26409 88345\n",
      "116856\n"
     ]
    }
   ],
   "source": [
    "print(len(soc), len(hlgt), len(hlt), len(pt), len(llt))\n",
    "print(len(soc) + len(hlgt) + len(hlt) + len(pt) + len(llt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48d0d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for n in range(len(soc)):\n",
    "    data.append({\n",
    "        \"level\": \"soc\",\n",
    "        \"term\": soc.loc[n, 'name']\n",
    "    })\n",
    "\n",
    "for n in range(len(hlgt)):\n",
    "    data.append({\n",
    "        \"level\": \"hlgt\",\n",
    "        \"term\": hlgt.loc[n, 'name']\n",
    "    })\n",
    "\n",
    "for n in range(len(hlt)):\n",
    "    data.append({\n",
    "        \"level\": \"hlt\",\n",
    "        \"term\": hlt.loc[n, 'name']\n",
    "    })\n",
    "\n",
    "for n in range(len(pt)):\n",
    "    data.append({\n",
    "        \"level\": \"pt\",\n",
    "        \"term\": pt.loc[n, 'name']\n",
    "    })\n",
    "\n",
    "for n in range(len(llt)):\n",
    "    data.append({\n",
    "        \"level\": \"llt\",\n",
    "        \"term\": llt.loc[n, 'name']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0138ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116856/116856 [13:28<00:00, 144.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing files...\n",
      "Closed: soc\n",
      "Closed: hlgt\n",
      "Closed: hlt\n",
      "Closed: pt\n",
      "Closed: llt\n",
      "All done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 設定\n",
    "ES_HOST = \"http://elasticsearch:9200\"\n",
    "ES_PASSWORD = \"micgm1Gemini\"\n",
    "es = Elasticsearch(ES_HOST, basic_auth=(\"elastic\", ES_PASSWORD))\n",
    "\n",
    "# 保存先ディレクトリ（ここに出力されます）\n",
    "output_dir = \"/workspace/99-NAS_data/pubmed/pubmed_meddra_sentence/\"\n",
    "base_filename = \"meddra_sentences\" \n",
    "\n",
    "fieldnames = [\"level\", \"term\", \"PMID\", \"SENTID\", \"SENTENCE\"]\n",
    "too_many_hits = []\n",
    "\n",
    "\n",
    "file_handles = {}\n",
    "csv_writers = {}\n",
    "\n",
    "try:\n",
    "    for i in tqdm(range(len(data))):\n",
    "        query_word = data[i][\"term\"]\n",
    "        current_level = data[i][\"level\"] # 現在のデータのlevelを取得\n",
    "\n",
    "        # --- ファイル管理ロジック ---\n",
    "        # そのlevelのファイルがまだ開かれていなければ作成する\n",
    "        if current_level not in file_handles:\n",
    "            # ファイル名を生成 (例: meddra_sentences_PT.csv)\n",
    "            filename = f\"{base_filename}_{current_level}.csv\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            \n",
    "            # ファイルを開く\n",
    "            f = open(filepath, mode='w', newline='', encoding='utf-8')\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            \n",
    "            # 辞書に登録\n",
    "            file_handles[current_level] = f\n",
    "            csv_writers[current_level] = writer\n",
    "        \n",
    "        # 対応するwriterを取得\n",
    "        writer = csv_writers[current_level]\n",
    "        # ------------------------\n",
    "\n",
    "        # 検索実行\n",
    "        search_body = { \n",
    "            \"query\": { \"multi_match\": { \"query\": query_word, \"fields\": [\"SENTENCE\"], \"type\": \"phrase\" } }, \n",
    "            \"sort\": [ {\"PMID\": {\"order\": \"asc\"}} ], \n",
    "            \"_source\": [\"PMID\", \"SENTID\", \"SENTENCE\"],\n",
    "            \"size\": 3 # 必要に応じて調整\n",
    "        }\n",
    "\n",
    "        res = es.search(index=\"pubmed_sentence_v2\", body=search_body)\n",
    "        total_hits = res['hits']['total']['value'] \n",
    "\n",
    "        if total_hits >= 1000:\n",
    "            too_many_hits.append(data[i])\n",
    "            continue\n",
    "        else:\n",
    "            row_list = []\n",
    "            for hit in res['hits']['hits']:\n",
    "                source = hit['_source']\n",
    "                row = {\n",
    "                    \"level\": current_level,\n",
    "                    \"term\": query_word,\n",
    "                    \"PMID\": source['PMID'],\n",
    "                    \"SENTID\": source['SENTID'],\n",
    "                    \"SENTENCE\": source['SENTENCE']\n",
    "                }\n",
    "                row_list.append(row)\n",
    "            \n",
    "            # 対応するlevelのファイルに書き込み\n",
    "            writer.writerows(row_list)\n",
    "\n",
    "finally:\n",
    "    # エラーが起きても起きなくても、最後に必ず全てのファイルを閉じる\n",
    "    print(\"Closing files...\")\n",
    "    for level, f in file_handles.items():\n",
    "        f.close()\n",
    "        print(f\"Closed: {level}\")\n",
    "\n",
    "print(\"All done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29f9c873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drugs with too many hits (>=1000): 12983\n"
     ]
    }
   ],
   "source": [
    "print(f\"Drugs with too many hits (>=1000): {len(too_many_hits)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93ddd718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12983 [00:00<?, ?it/s]/tmp/ipykernel_422850/2848636323.py:55: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  page = es.search(\n",
      "100%|██████████| 12983/12983 [4:01:48<00:00,  1.12s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing files...\n",
      "Closed: soc\n",
      "Closed: hlgt\n",
      "Closed: hlt\n",
      "Closed: pt\n",
      "Closed: llt\n",
      "All done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 設定（前半と同じパス・ファイル名である必要があります）\n",
    "output_dir = \"/workspace/99-NAS_data/pubmed/pubmed_meddra_sentence/\"\n",
    "base_filename = \"meddra_sentences\"\n",
    "fieldnames = [\"level\", \"term\", \"PMID\", \"SENTID\", \"SENTENCE\"]\n",
    "\n",
    "# ファイルハンドラ管理用\n",
    "file_handles = {}\n",
    "csv_writers = {}\n",
    "\n",
    "try:\n",
    "    for item in tqdm(too_many_hits):\n",
    "        query_word = item[\"term\"]\n",
    "        current_level = item[\"level\"]\n",
    "\n",
    "        # --- ファイル管理ロジック (追記モード) ---\n",
    "        if current_level not in file_handles:\n",
    "            filename = f\"{base_filename}_{current_level}.csv\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            \n",
    "            # ファイルが存在するか確認（ヘッダーを書くかどうかの判定用）\n",
    "            file_exists = os.path.exists(filepath)\n",
    "            \n",
    "            # ★重要: mode='a' (追記モード) で開く\n",
    "            f = open(filepath, mode='a', newline='', encoding='utf-8')\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            \n",
    "            # もし前半の処理でファイルが作られていなかった場合だけヘッダーを書く\n",
    "            if not file_exists:\n",
    "                writer.writeheader()\n",
    "            \n",
    "            file_handles[current_level] = f\n",
    "            csv_writers[current_level] = writer\n",
    "        \n",
    "        writer = csv_writers[current_level]\n",
    "        # ------------------------------------\n",
    "\n",
    "        search_body = {\n",
    "            \"query\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query_word,\n",
    "                    \"fields\": [\"SENTENCE\"],\n",
    "                    \"type\": \"phrase\"\n",
    "                }\n",
    "            },\n",
    "            \"_source\": [\"PMID\", \"SENTID\", \"SENTENCE\"],\n",
    "            # Scroll時は _doc 順が一番速い\n",
    "            \"sort\": [{\"_doc\": \"asc\"}]\n",
    "        }\n",
    "\n",
    "        # Scroll検索開始\n",
    "        page = es.search(\n",
    "            index=\"pubmed_sentence_v2\",\n",
    "            body=search_body,\n",
    "            scroll=\"5m\", # 少し長めに\n",
    "            size=1000\n",
    "        )\n",
    "\n",
    "        sid = page['_scroll_id']\n",
    "        hits = page['hits']['hits']\n",
    "        \n",
    "        try:\n",
    "            while len(hits) > 0:\n",
    "                row_list = []\n",
    "                for hit in hits:\n",
    "                    source = hit['_source']\n",
    "                    row_list.append({\n",
    "                        \"level\": current_level,\n",
    "                        \"term\": query_word,\n",
    "                        \"PMID\": source['PMID'],\n",
    "                        \"SENTID\": source['SENTID'],\n",
    "                        \"SENTENCE\": source['SENTENCE']\n",
    "                    })\n",
    "                \n",
    "                # 該当レベルのファイルに書き込み\n",
    "                writer.writerows(row_list)\n",
    "                \n",
    "                # 次のページへ\n",
    "                page = es.scroll(scroll_id=sid, scroll=\"5m\")\n",
    "                sid = page['_scroll_id']\n",
    "                hits = page['hits']['hits']\n",
    "        \n",
    "        finally:\n",
    "            # 1単語の全件取得が終わったら、Scroll IDを削除してメモリ解放（重要）\n",
    "            es.clear_scroll(scroll_id=sid)\n",
    "\n",
    "finally:\n",
    "    # 最後に全てのファイルを閉じる\n",
    "    print(\"Closing files...\")\n",
    "    for level, f in file_handles.items():\n",
    "        f.close()\n",
    "        print(f\"Closed: {level}\")\n",
    "\n",
    "print(\"All done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
